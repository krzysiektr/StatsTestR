<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />


<meta name="author" content="Krzysztof Trajkowski" />


<title>Rozdział 1</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/flatly.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-5.0.13/css/fa-svg-with-js.css" rel="stylesheet" />
<script src="site_libs/font-awesome-5.0.13/js/fontawesome-all.min.js"></script>
<script src="site_libs/font-awesome-5.0.13/js/fa-v4-shims.min.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 60px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 65px;
  margin-top: -65px;
}

.section h2 {
  padding-top: 65px;
  margin-top: -65px;
}
.section h3 {
  padding-top: 65px;
  margin-top: -65px;
}
.section h4 {
  padding-top: 65px;
  margin-top: -65px;
}
.section h5 {
  padding-top: 65px;
  margin-top: -65px;
}
.section h6 {
  padding-top: 65px;
  margin-top: -65px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>


<div class="container-fluid main-container">

<!-- tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});
</script>

<!-- code folding -->






<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html"></a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">
    <span class="fa fa-home"></span>
     
    Statystyka w R
  </a>
</li>
<li>
  <a href="Statystyka_w_R_R01.html">Wprowadzenie do testowania</a>
</li>
<li>
  <a href="Statystyka_w_R_R02.html">Metody klasyczne / odporne</a>
</li>
<li>
  <a href="Statystyka_w_R_R03.html">Metody oparte na rangach</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Rozdział 1</h1>
<h4 class="author"><em>Krzysztof Trajkowski</em></h4>
<h4 class="date"><em>24 września, 2018</em></h4>

</div>

<div id="TOC">
<ul>
<li><a href="#part_1">Wprowadzenie do testowania</a><ul>
<li><a href="#part_11">Weryfikacja hipotezy statystycznej</a></li>
<li><a href="#part_12">Testowanie parametrów</a><ul>
<li><a href="#part_121">Testy dla parametru położenia</a></li>
<li><a href="#part_122">Testy dla parametru skali</a></li>
</ul></li>
<li><a href="#testowanie-zaozen">Testowanie założeń</a><ul>
<li><a href="#testy-losowosci">Testy losowości</a></li>
<li><a href="#testy-normalnosci">Testy normalności</a></li>
<li><a href="#testy-jednorodnosci-wariancji">Testy jednorodności wariancji</a></li>
</ul></li>
</ul></li>
<li><a href="#references">References</a></li>
</ul>
</div>

<div id="part_1" class="section level1">
<h1>Wprowadzenie do testowania</h1>
<div id="part_11" class="section level2">
<h2>Weryfikacja hipotezy statystycznej</h2>
<p>Estymator nieznanego parametru <span class="math inline">\(\theta\)</span> jest zmienną losową ponieważ z <span class="math inline">\(m\)</span> niezależnych losowań próbek otrzymamy <span class="math inline">\(m\)</span> różnych wartości estymatorów tzn. <span class="math inline">\(\hat{\theta}_1,\,\hat{\theta}_2,\,...,\,\hat{\theta}_m\)</span>. Jeśli dysponujemy dużą próbą (często przyjmuje się, że <span class="math inline">\(n\)</span>&gt;30) to rozkład badanego estymatora można aproksymować rozkładem normalnym <span class="math inline">\(N(\hat{\theta},SE_{\hat{\theta}})\)</span>. Estymator <span class="math inline">\(\hat{\theta}\)</span> i jego błąd standardowy <span class="math inline">\(SE_{\hat{\theta}}\)</span> można wyznaczyć za pomocą wielu funkcji dostępnych w R:</p>
<ul>
<li><p>średnia: <span class="math inline">\(\; \hat{\mu}=\sum_{i=1}^{n}x_i/n\)</span> <span class="math inline">\(\;\longrightarrow\quad\)</span> <a href="https://www.rdocumentation.org/packages/base/versions/3.4.1/topics/mean"><code>mean</code></a> <span class="math inline">\(\quad/\quad\)</span> <span class="math inline">\(\; SE_{\hat{\mu}}=\sqrt{\hat{\sigma}^2/n}\)</span> <span class="math inline">\(\;\longrightarrow\quad\)</span> <a href="https://www.rdocumentation.org/packages/asympTest/versions/0.1.3/topics/seMean"><code>seMean</code></a></p></li>
<li><p>wariancja: <span class="math inline">\(\;\hat{\sigma}^2=\frac{\sum_{i=1}^{n}(x_i-\hat{\mu})^2}{n-1}\)</span> <span class="math inline">\(\;\longrightarrow\quad\)</span> <a href="https://www.rdocumentation.org/packages/stats/versions/3.4.1/topics/cor"><code>var</code></a> <span class="math inline">\(\quad/\quad\)</span> <span class="math inline">\(\;SE_{\hat{\sigma}^2}=\sqrt{\frac{\sum_{i=1}^{n}\big((x_i-\hat{\mu})^2-\hat{\sigma}^2_*\big)^2}{n\cdot(n-1)}}\)</span> <span class="math inline">\(\;\longrightarrow\quad\)</span> <a href="https://www.rdocumentation.org/packages/asympTest/versions/0.1.3/topics/seMean"><code>seVar</code></a></p></li>
</ul>
<p><span class="math inline">\(\quad\textrm{dla}\quad\hat{\sigma}^2_*=\sum_{i=1}^{n}(x_i-\hat{\mu})^2/n\)</span></p>
<p>Zauważmy, że badanym estymatorem <span class="math inline">\(\hat{\theta}\)</span> może być np. różnica lub iloraz dwóch parametrów.</p>
<ul>
<li><p>błąd różnicy / ilorazu dwóch średnich: <span class="math inline">\(\;SE_{\hat{\mu_1}-\hat{\mu_2}}\)</span> <span class="math inline">\(\;\longrightarrow\quad\)</span> <a href="https://www.rdocumentation.org/packages/asympTest/versions/0.1.3/topics/seMean"><code>seDMean</code></a> <span class="math inline">\(\quad/\quad\)</span> <span class="math inline">\(\;SE_{\hat{\mu}_1/\hat{\mu}_2}\)</span> <span class="math inline">\(\;\longrightarrow\quad\)</span> <a href="https://www.rdocumentation.org/packages/asympTest/versions/0.1.3/topics/seMean"><code>seRMean</code></a></p></li>
<li><p>błąd różnicy / ilorazu dwóch wariancji: <span class="math inline">\(\;\)</span> <span class="math inline">\(SE_{\hat{\sigma}_1^2-\hat{\sigma}_2^2}\)</span> <span class="math inline">\(\;\longrightarrow\quad\)</span> <a href="https://www.rdocumentation.org/packages/asympTest/versions/0.1.3/topics/seMean"><code>seDVar</code></a> <span class="math inline">\(\quad/\quad\)</span> <span class="math inline">\(SE_{\hat{\sigma}_1^2/\hat{\sigma}_2^2}\)</span> <span class="math inline">\(\;\longrightarrow\quad\)</span> <a href="https://www.rdocumentation.org/packages/asympTest/versions/0.1.3/topics/seMean"><code>seRVar</code></a></p></li>
</ul>
<p>Warto w tym miejscu zwrócić uwagę na funkcję <a href="https://www.rdocumentation.org/packages/asbio/versions/1.4-2/topics/win"><code>win</code></a> za pomocą której wartości z próbki można poddać procesowi winsoryzacji. Taki zabieg jest stosowany do konstrukcji odpornych estymatorów np. <a href="https://pl.wikipedia.org/wiki/%C5%9Arednia_winsorowska">średniej winsorowskiej</a>.</p>
<ul>
<li><p>średnia winsorowska <span class="math inline">\(\hat{\mu}_w\;\longrightarrow\quad\)</span> <a href="https://www.rdocumentation.org/packages/WRS2/versions/0.9-2/topics/trimse"><code>winmean</code></a> <span class="math inline">\(\quad/\quad\)</span> błąd średniej winsorowskiej: <span class="math inline">\(SE_{\hat{\mu}_{w}}\)</span> <span class="math inline">\(\;\longrightarrow\quad\)</span> <a href="https://www.rdocumentation.org/packages/WRS2/versions/0.9-2/topics/trimse"><code>winmse</code></a></p></li>
<li><p>średnia ucięta <span class="math inline">\(\hat{\mu}_t\)</span> <span class="math inline">\(\;\longrightarrow\quad\)</span> <a href="https://www.rdocumentation.org/packages/base/versions/3.4.1/topics/mean"><code>mean</code></a> <span class="math inline">\(\quad/\quad\)</span> błąd średniej uciętej: <span class="math inline">\(SE_{\hat{\mu}_{t}}\)</span> <span class="math inline">\(\;\longrightarrow\quad\)</span> <a href="https://www.rdocumentation.org/packages/WRS2/versions/0.9-2/topics/trimse"><code>trimse</code></a></p></li>
<li><p>kwantyle <span class="math inline">\(\hat{q}_{HD}\)</span> <span class="math inline">\(\quad/\quad\)</span> błąd kwantyla: <span class="math inline">\(SE_{\hat{q}_{HD}}\)</span> <span class="math inline">\(\;\longrightarrow\quad\)</span> <a href="https://www.rdocumentation.org/packages/Hmisc/versions/4.0-3/topics/hdquantile"><code>hdquantile</code></a></p></li>
</ul>
<p>Metody symulacyjne są często stosowane gdy nie wiemy z jakiego rozkładu pochodzi zmienna losowa. Przypomnijmy, np. metoda bootstrap polega na wielokrotnym losowaniu ze zwracaniem z próby w celu wyznaczenia <span class="math inline">\(B\)</span> estymatorów <span class="math inline">\(\hat{\theta}\)</span>. Inaczej mówiąc, tworzymy wektor <span class="math inline">\(\hat{\theta}_i^*=[\hat{\theta}_1,\;\hat{\theta}_2,\;\dots,\;\hat{\theta}_B]\)</span> i na jego podstawie obliczamy średnią (szacunek estymatora) oraz odchylenie standardowe (błąd estymatora). Do wyznaczenia wektora <span class="math inline">\(\hat{\theta}^*_i\)</span> oraz estymacji parametru <span class="math inline">\(\theta\)</span> można wykorzystać funkcję <a href="https://www.rdocumentation.org/packages/boot/versions/1.3-19/topics/boot"><code>boot</code></a>. Innym rozwiązaniem jest zastosowanie funkcji <a href="https://www.rdocumentation.org/packages/base/versions/3.4.1/topics/lapply"><code>replicate</code></a> lub <a href="https://www.rdocumentation.org/packages/base/versions/3.4.1/topics/lapply"><code>lapply</code></a> w połączeniu z funkcją <a href="https://www.rdocumentation.org/packages/base/versions/3.4.1/topics/sample"><code>sample</code></a> a następnie obliczenie wartości estymatora i jego błąd standardowy odpowiednio z wykorzystaniem funkcji <a href="https://www.rdocumentation.org/packages/base/versions/3.4.1/topics/mean"><code>mean</code></a> i <a href="https://www.rdocumentation.org/packages/stats/versions/3.4.1/topics/sd"><code>sd</code></a>. Dodajmy, że metody symulacyjne do których należy metoda bootstrap są bardzo wymagające obliczeniowo. Warto więc podkreślić, że w funkcji <a href="https://www.rdocumentation.org/packages/boot/versions/1.3-19/topics/boot"><code>boot</code></a> są dostępne opcje które umożliwiają zaangażowanie wybranej liczby rdzeni procesora do obliczeń. Również funkcja <a href="https://www.rdocumentation.org/packages/base/versions/3.4.1/topics/lapply"><code>lapply</code></a> ma swój wielordzeniowy odpowiednik - funkcja <a href="https://www.rdocumentation.org/packages/parallel/versions/3.4.1/topics/mclapply"><code>mclapply</code></a> z pakietu <a href="https://www.rdocumentation.org/packages/parallel/versions/3.4.1"><code>parallel</code></a>.</p>
<p>Na podstawie dystrybuanty empirycznej (funkcja <a href="https://www.rdocumentation.org/packages/stats/versions/3.4.1/topics/ecdf"><code>ecdf</code></a>) lub teoretycznej (funkcja <a href="https://www.rdocumentation.org/packages/stats/versions/3.4.1/topics/Normal"><code>pnorm</code></a>) można wyznaczyć prawdopodobieństwo czyli p-wartość i podjąć decyzję o odrzuceniu lub braku podstaw do odrzucenia hipotezy zerowej. Inaczej mówiąc, odrzucamy hipotezę zerową gdy p-wartość<span class="math inline">\(&lt;\alpha\)</span> natomiast brak jest podstaw do jej odrzucenia gdy p-wartość<span class="math inline">\(&gt;\alpha\)</span>. Najczęściej przyjmuje się, że poziom istotności <span class="math inline">\(\alpha=0,05\)</span>.</p>
<p><span class="math display">\[
\begin{aligned}
H_{0}:\;\theta=\theta_{0}\quad\textrm{vs.}\quad H_{1}:\;\theta\neq\theta_{0}\quad\longrightarrow\quad
&amp;
\textrm{p-wartość}=2\;\textrm{min}\;(p,1-p)
&amp;
\textrm{(test dwustronny)}
\end{aligned}
\]</span> Wartość <span class="math inline">\(p\)</span> czyli prawdopodobieństwo obliczamy na podstawie dystrybuanty empirycznej lub teoretycznej. Dla metody bootstrap: <span class="math inline">\(p=P(\hat{\theta}^*\leq\theta_0)\)</span> natomiast dla metody asymptotycznej: <span class="math inline">\(p=P(\theta_0,\,\hat{\theta},SE_{\hat{\theta}})\)</span>.</p>
<pre class="r"><code># wygenerowanie wektora liczb:
set.seed(2305); x &lt;- rnorm(30, 0,1)
# błąd standardowy średniej:
SE_mu &lt;- sqrt(var(x)/length(x))
# estymator średniej:
MU &lt;- mean(x)
# prawdopodobieństwo z rozkładu normalnego dla testowej wartości:
p &lt;- pnorm(0,MU,SE_mu)
# p-wartość:
2*min(p, 1-p)</code></pre>
<pre><code>## [1] 0.01203982</code></pre>
<pre class="r"><code>set.seed(2305); m &lt;- replicate(10000, mean(sample(x,30,T)))
p &lt;- mean(m&lt;0)
2*min(p, 1-p)</code></pre>
<pre><code>## [1] 0.011</code></pre>
<p>Decyzję o odrzuceniu (lub nie) hipotezy zerowej można podjąć również w oparciu o przedział ufności z wykorzystaniem kwantyli z rozkładu normalnego – <a href="https://www.rdocumentation.org/packages/stats/versions/3.1.1/topics/Normal"><code>qnorm</code></a>: <span class="math display">\[\theta=\hat{\theta}\pm z_{\alpha/2}\cdot SE_{\hat{\theta}}\]</span></p>
<pre class="r"><code>qn &lt;- qnorm(0.05/2,0,1)
c(MU+qn*SE_mu, MU-qn*SE_mu)</code></pre>
<pre><code>## [1] 0.08477817 0.68789557</code></pre>
<p>W przypadku bootstrapowej metody percentyli wystarczy obliczyć odpowiedni kwantyl za pomocą funkcji <a href="https://www.rdocumentation.org/packages/stats/versions/3.4.1/topics/quantile"><code>quantile</code></a> lub <a href="https://www.rdocumentation.org/packages/Hmisc/versions/4.0-3/topics/hdquantile"><code>hdquantile</code></a>. Dla dwustronnego przedziału ufności będzie to <span class="math inline">\(q_{\alpha/2}\)</span> oraz <span class="math inline">\(q_{1-\alpha/2}\)</span>. Jeśli wartość badanego estymatora znajdzie się w przedziale ufności to jest barak podstaw do odrzucenia hipotezy zerowej. W sytuacji odwrotnej hipotezę zerową odrzucamy. Do wyznaczenia przedziału ufności można wykorzystać również funkcję <a href="https://www.rdocumentation.org/packages/boot/versions/1.3-19/topics/boot.ci"><code>boot.ci</code></a> która oprócz metody percentyli oferuje także inne rozwiązania np. metodę Bias-Corrected Bootstrap.</p>
<pre class="r"><code>quantile(m, c(0.025,0.975))</code></pre>
<pre><code>##       2.5%      97.5% 
## 0.08690072 0.68998722</code></pre>
<p>Powyżej przedstawione obliczenia miały na celu pokazać proces dochodzenia do wyniku końcowego tzn. jak obliczyć przedział ufności lub p-wartość. W praktyce stosujemy gotowe rozwiązania które są zaimplementowane w pakietach statystycznych i zostaną przedstawione w dalszej części tego opracowania.</p>
</div>
<div id="part_12" class="section level2">
<h2>Testowanie parametrów</h2>
<div id="part_121" class="section level3">
<h3>Testy dla parametru położenia</h3>
<p>Najczęściej hipotezy satystyczne są weryfikowane w oparciu o średnią z wykorzystaniem rozkładu t-Studenta. Dla dużej próby częstą praktyką jest przybliżanie rozkładu t-Studenta za pomocą rozkładu normalnego. <span class="math display">\[SE_{\hat{\mu}}=\sqrt{\hat{\sigma}^2/n}\]</span> gdzie: <span class="math inline">\(\hat{\sigma}^2\)</span> to nieobciążony estymator wariancji oraz <span class="math inline">\(n\)</span> to liczebność próby.</p>
<pre class="r"><code>asympTest::asymp.test(x)</code></pre>
<pre><code>## 
##  One-sample asymptotic mean test
## 
## data:  x
## statistic = 2.511, p-value = 0.01204
## alternative hypothesis: true mean is not equal to 0
## 95 percent confidence interval:
##  0.08477817 0.68789557
## sample estimates:
##      mean 
## 0.3863369</code></pre>
<p>Jednak gdy dane pochodzą z rozkładu innego niż normalny (rozkład skośny, obserwacje odstające itp.) stosowanie testu t-Studenta nie jest dobrym wyborem. Jednym z możliwych rozwiązań jest zweryfikowanie hipotezy statystycznej w oparciu o odporne estymatory. Ich szerszy opis można znaleźć w pracy <span class="citation">(Wilcox Rand <a href="#ref-wilcox2017">2017</a>)</span>. Przykładowo, błąd standardowy dla średniej uciętej <span class="citation">(Tukey and McLaughlin <a href="#ref-tmc1963">1963</a>)</span> ma wzór: <span class="math display">\[SE_{\hat{\mu}_t}=\sqrt{s_w^2/(1-2G)^2\;n}\]</span></p>
<p>gdzie: <span class="math inline">\(s_w^2=\frac{1}{n-1}\sum_{i=1}^{n}(w_i-\bar{x}_w)^2\)</span> to wariancja winsorowska, <span class="math inline">\(w_i\)</span> to wartości z oryginalnej próbki poddanej procesowi winsoryzacji, <span class="math inline">\(G\)</span> to proporcja wartości przyciętych.</p>
<pre class="r"><code>WRS::trimci(x, tr= 0.2, null.value= 0, pr= F)</code></pre>
<pre><code>## $ci
## [1] 0.02059015 0.75001132
## 
## $estimate
## [1] 0.3853007
## 
## $test.stat
## [1] 2.228928
## 
## $se
## [1] 0.1728637
## 
## $p.value
## [1] 0.03960048
## 
## $n
## [1] 30</code></pre>
<p>Warto zauważyć, że dla parametru obcięcia równego <span class="math inline">\(G=0\)</span> wzór zostanie uproszczony do klasycznej wersji testu t-Studenta. Inaczej mówiąc, średnia ucięta i wariancja winsorowska będą równe odpowiednio średniej arytmetycznej i wariancji. Natomiast dla <span class="math inline">\(G=0.5\)</span> możemy otrzymać estymator mediany, ale wnioskowanie o medianie za pomocą tej metody nie powinno być wykonywane. Dla rozkładów ciągłych opracowano metodę budowy przedziału ufności mediany w oparciu o błąd standardowy <span class="citation">(McKean and Schrader <a href="#ref-ms1984">1984</a>)</span>. <span class="math display">\[SE_{\hat{m}}=\frac{x_{n-k+1}-x_{k}}{2\cdot z_{\,0.995}}\]</span> gdzie: <span class="math inline">\(k=\frac{n+1}{2}-z_{\,0.995}\cdot\sqrt{\frac{n}{4}}\)</span> oraz <span class="math inline">\(z_{0.995}\)</span> to kwantyl rzędu <span class="math inline">\(99.5\%\)</span> z rozkładu normalnego.</p>
<pre class="r"><code>WRS::msmedci(x, nullval= 0)</code></pre>
<pre><code>## $test
## [1] 0.8153327
## 
## $ci.low
## [1] -0.289024
## 
## $ci.hi
## [1] 0.7007735
## 
## $p.value
## [1] 0.4148819
## 
## $median
## [1] 0.2058748</code></pre>
<p>Inne rozwiązanie to konstrukcja przedziału ufności w oparciu o interpolację <span class="citation">(Hettmansperger and Sheather <a href="#ref-hs1986">1986</a>)</span> oraz jego uogólnienie na dowolne kwantyle <span class="citation">(Nyblom <a href="#ref-nb1992">1992</a>)</span>. Dodajmy jeszcze, że dobrą propozycją jest stosowanie estymatorów z wykorzystaniem rozkładu beta <span class="citation">(Maritz and Jarrett <a href="#ref-mj1978">1978</a>)</span> lub <span class="citation">(Harrel and Davis <a href="#ref-hd1982">1982</a>)</span>. Ostatnie rozwiązanie w wersji bootstrap jest często proponowane gdy występują duplikaty w próbce.</p>
<pre class="r"><code>WRS::hdpb(x, est= WRS::hd, alpha= 0.05, nboot= 2000, SEED= TRUE, nv= 0)</code></pre>
<pre><code>## $ci
## [1] -0.01433357  0.80222278
## 
## $n
## [1] 30
## 
## $estimate
## [1] 0.3207006
## 
## $p.value
## [1] 0.058</code></pre>
</div>
<div id="part_122" class="section level3">
<h3>Testy dla parametru skali</h3>
<p>Do badania parametru skali można zweryfikować hipotezę statystyczną dotyczącą np. wariancji tzn.: <span class="math display">\[H_{0}:\;\sigma^2=\sigma^2_0\quad\textrm{vs.}\quad H_{1}:\;\sigma^2\neq\sigma^2_0\]</span> W takiej sytuacji przeważnie proponowane jest klasyczne rozwiązanie czyli test chi-kwadrat w którym zakładamy, że badana zmienna ma rozkład normalny. <span class="math display">\[\chi^2=\frac{(n-1)\hat{\sigma}^2}{\sigma^2_0}\quad\longrightarrow\quad\chi^2_{df=n-1}\]</span></p>
<pre class="r"><code>DescTools::VarTest(x, sigma.squared= 1)</code></pre>
<pre><code>## 
##  One Sample Chi-Square test on variance
## 
## data:  x
## X-squared = 20.595, df = 29, p-value = 0.2531
## alternative hypothesis: true variance is not equal to 1
## 95 percent confidence interval:
##  0.450442 1.283427
## sample estimates:
## variance of x 
##     0.7101806</code></pre>
<p>Podobnie jak w przypadku badania parametru położenia (centralne twierdzenie graniczne) można obliczyć błąd standardowy dla wariancji: <span class="math display">\[SE_{\hat{\sigma}^2}=\sqrt{\textrm{Var}(x_i-\hat{\mu})^2/n}=\sqrt{\sum_{i=1}^{n}\big((x_i-\hat{\mu})^2-\hat{\sigma}^2_*\big)^2/\big(n\cdot(n-1)\big)}\]</span> gdzie: <span class="math inline">\(\textrm{Var}(x_i):\hat{\sigma}^2=\sum_{i=1}^{n}(x_i-\hat{\mu})^2/(n-1)\)</span> to estymator wariancji, <span class="math inline">\(\hat{\sigma}^2_*=\sum_{i=1}^{n}(x_i-\hat{\mu})^2/n\)</span> to obciążony estymator wariancji. <span class="math display">\[Z=\frac{\hat{\sigma}^2-\sigma^2_{0}}{SE_{\hat{\sigma}^2}}\quad\longrightarrow\quad N(0,1)\]</span></p>
<pre class="r"><code>asympTest::asymp.test(x, par= &quot;var&quot;, ref= 1)</code></pre>
<pre><code>## 
##  One-sample asymptotic variance test
## 
## data:  x
## statistic = -1.7995, p-value = 0.07195
## alternative hypothesis: true variance is not equal to 1
## 95 percent confidence interval:
##  0.3945105 1.0258507
## sample estimates:
##  variance 
## 0.7101806</code></pre>
<p>Dla małych prób można wykonać symulację komputerową np. bootstrapową metodę percentyli za pomocą funkcji <a href="https://www.rdocumentation.org/packages/wBoot/versions/1.0.3/topics/boot.one.per"><code>boot.one.per</code></a>.</p>
<pre class="r"><code>wBoot::boot.one.per(x, var, null.hyp= 1, R= 10000)</code></pre>
<pre><code>## 
## 
##  RESULTS OF PERCENTILE BOOTSTRAP FOR VAR 
## 
##     SUMMARY Variable  n Statistic  Observed
##  STATISTICS        x 30       var 0.7101806
## 
##  BOOTSTRAP Replications     Mean        SE    Bias Percent.bias
##    SUMMARY        10000 0.687665 0.1643287 -0.0225         3.17
## 
##  HYPOTHESIS Null Alternative P.value
##        TEST    1   not-equal  0.0783
## 
##  CONFIDENCE Level      Type Confidence.interval
##    INTERVAL   95% two-sided     (0.3975, 1.048)</code></pre>
</div>
</div>
<div id="testowanie-zaozen" class="section level2">
<h2>Testowanie założeń</h2>
<div id="testy-losowosci" class="section level3">
<h3>Testy losowości</h3>
<p>Założenie losowości próby (np. brak autokorelacji, trendu) można zweryfikować na podstawie testu serii <span class="citation">(Wald and Wolfowitz <a href="#ref-wald1940">1940</a>)</span> w którym zliczamy wszystkie sekwencje - liczba serii. Dokładną p-wartość obliczamy na podstawie wzorów:</p>
<ul>
<li>parzysta liczby serii:</li>
</ul>
<p><span class="math display">\[P(R=2k)=\frac{2\cdot C^{n_1-1}_{k-1}\cdot C^{n_2-1}_{k-1}}{C^{n_1+n_2}_{n_1}}\quad\textrm{dla}\quad k=R/2\]</span></p>
<ul>
<li>nieparzysta liczba serii:</li>
</ul>
<p><span class="math display">\[P(R=2k+1)=\frac{C^{n_1-1}_{k-1}\cdot C^{n_2-1}_{k}+C^{n_1-1}_{k}\cdot C^{n_2-1}_{k-1}}{C^{n_1+n_2}_{n_1}}\quad\textrm{dla}\quad k=(R-1)/2\]</span></p>
<pre class="r"><code>randtests::druns(2, 6, 9)+ randtests::druns(3, 6, 9)</code></pre>
<pre><code>## [1] 0.002997003</code></pre>
<pre class="r"><code>randtests::pruns(3, 6, 9)</code></pre>
<pre><code>## [1] 0.002997003</code></pre>
<p>Ze względu na wielkość próby wyznaczenie dokładnej p-wartości nie jest zawsze możliwe. Dla dużych prób rozkład liczby serii można wyznaczyć w sposób symulacyjny lub aproksymować go za pomocą rozkładu normalnego.</p>
<p><span class="math display">\[Z=\frac{R+h-E(R)}{\sqrt{V(R)}}\quad\longrightarrow\quad N(0,1)\]</span> gdzie: <span class="math inline">\(E(R)=\frac{2n_1n_2}{n_1+n_2}+1\)</span> to wartość średnia, <span class="math inline">\(V(R)=\frac{2n_1 n_2(2n_1 n_2-n_1n_2)}{(n_1+n_2)^2(n_1+n_2-1)}\)</span> to wariancja, <span class="math inline">\(h=\pm 0,5\)</span> to korekta na ciągłość. Jeśli <span class="math inline">\(R&lt;E(R)\)</span> to <span class="math inline">\(h=0,5\)</span> natomiast w sytuacji odwrotnej tzn. <span class="math inline">\(R&gt;E(R)\)</span> mamy <span class="math inline">\(h=-0,5\)</span>.</p>
<pre class="r"><code>set.seed(2305); x &lt;- sample(1:30, 40, T)</code></pre>
<pre class="r"><code>DescTools::RunsTest(x, exact= FALSE, correct= TRUE)</code></pre>
<pre><code>## 
##  Runs Test for Randomness
## 
## data:  x
## z = -1.1213, runs = 17, m = 20, n = 20, p-value = 0.2622
## alternative hypothesis: true number of runs is not equal the expected number
## sample estimates:
## median(x) 
##      17.5</code></pre>
<p>Warto podkreślić, że metod testowania losowości jest więcej <span class="citation">(Wang <a href="#ref-Wang2003">2003</a>)</span> a niektóre z nich mogą mieć większą moc niż test serii. Przykładem może być test losowości von Neumanna oparty na rangach <span class="citation">(Bartels <a href="#ref-bar1982">1982</a>)</span>.</p>
<pre class="r"><code>randtests::bartels.rank.test(x, pvalue=&quot;normal&quot;)</code></pre>
<pre><code>## 
##  Bartels Ratio Test
## 
## data:  x
## statistic = -0.90068, n = 40, p-value = 0.3678
## alternative hypothesis: nonrandomness</code></pre>
</div>
<div id="testy-normalnosci" class="section level3">
<h3>Testy normalności</h3>
<p>Do badania normalności rozkładu w języku R można skorzystać z wielu metod <span class="citation">(P. Lafaye de Micheaux and Tran <a href="#ref-lafa2016">2016</a>)</span> które mają swoje mocne i słabe strony <span class="citation">(Biecek <a href="#ref-biecek2013">2013</a>)</span>. Inaczej mówiąc nie ma jednej uniwersalnej procedury która sprawdzi się dobrze w każdych warunkach. Warto dodać, że pomimo wielu ciekawych rozwiązań np. test oparty na entropii <span class="citation">(Miecznikowski, Vexler, and Shepherd <a href="#ref-dbgof2013">2013</a>)</span> test Shapiro-Wilka wciąż cieszy się największą popularnością.</p>
<pre class="r"><code>shapiro.test(x)</code></pre>
<pre><code>## 
##  Shapiro-Wilk normality test
## 
## data:  x
## W = 0.93735, p-value = 0.02816</code></pre>
<pre class="r"><code>dbEmpLikeGOF::dbEmpLikeGOF(x, testcall= &quot;normal&quot;, pvl.Table= F, vrb= F)</code></pre>
<pre><code>## $teststat
## [1] 13.35399
## 
## $pvalue
## [1] 0.003</code></pre>
</div>
<div id="testy-jednorodnosci-wariancji" class="section level3">
<h3>Testy jednorodności wariancji</h3>
<p>Badanie homogeniczności wariancji sprowadza się do porównania dwóch lub kilku zmiennych pod kątem równości wariancji. W przypadku dwóch zmiennych bardzo częstym wyborem jest test F czyli klasyczne rozwiązanie w którym zakładamy, że zmienne mają rozkład normalny. <span class="math display">\[F=\frac{\hat{\sigma}^2_1}{\hat{\sigma}^2_2\;r_0}\quad\longrightarrow\quad F_{df_1=n_1-1,\;df_2=n_2-1}\]</span> gdzie: <span class="math inline">\(\hat{\sigma}^2_k=\frac{\sum_{i=1}^{n}(x_i-\hat{\mu})^2}{n-1}\)</span> to wariancje dla <span class="math inline">\(k=1,2\)</span>.</p>
<pre class="r"><code>set.seed(2305); d &lt;- data.frame(x= rnorm(20, 0,1), y= rnorm(20, 0,2))</code></pre>
<pre class="r"><code>with(DescTools::VarTest(x, y, ratio= 1), data= d)</code></pre>
<pre><code>## 
##  F test to compare two variances
## 
## data:  x and y
## F = 0.29865, num df = 19, denom df = 19, p-value = 0.0115
## alternative hypothesis: true ratio of variances is not equal to 1
## 95 percent confidence interval:
##  0.1182075 0.7545128
## sample estimates:
## ratio of variances 
##          0.2986454</code></pre>
<p>Ciekawą alternatywą jest testowanie wariancji w oparciu o centralne twierdzenie graniczne <span class="citation">(Coeurjolly et al. <a href="#ref-asym2009">2009</a>)</span> za pomocą której można zweryfikować jedną z wybranych hipotez zerowych:</p>
<ol style="list-style-type: decimal">
<li>iloraz dwóch wariancji: <span class="math display">\[H_{0}:\;\sigma^2_1/\sigma^2_2=r_0\quad\textrm{vs.}\quad H_{1}:\;\sigma^2_1/\sigma^2_2\neq r_0\]</span> Statystyka testu: <span class="math display">\[Z=\frac{\hat{\sigma}^2_1/\hat{\sigma}^2_2-r_0}{SE_{\hat{\sigma}^2_1/\hat{\sigma}^2_2}}\quad\longrightarrow\quad N(0,1)\]</span> gdzie: <span class="math inline">\(SE_{\hat{\sigma}^2_1/\hat{\sigma}^2_2}=\frac{1}{\hat{\sigma}^2_{2}}\sqrt{\frac{\textrm{Var}(x_{i}-\hat{\mu})^2}{n_1}+r^2_{}\cdot \frac{\textrm{Var}(y_i-\hat{\mu})^2}{n_2}}\)</span> to błąd standardowy iloczynu wariancji, <span class="math inline">\(r^2\)</span> to iloczyn wariancji podniesiony do drugiej potęgi tzn. <span class="math inline">\(\big(\textrm{Var}(x_i)/\textrm{Var}(y_i)\big)^2=\big(\hat{\sigma}_1^2/\hat{\sigma}_2^2\big)^2\)</span></li>
</ol>
<pre class="r"><code>asympTest::asymp.test(d$x, d$y, par= &quot;rVar&quot;, ref= 1)</code></pre>
<pre><code>## 
##  Two-sample asymptotic ratio of variances test
## 
## data:  d$x and d$y
## statistic = -6.3445, p-value = 2.231e-10
## alternative hypothesis: true ratio of variances is not equal to 1
## 95 percent confidence interval:
##  0.08198055 0.51531016
## sample estimates:
## ratio of variances 
##          0.2986454</code></pre>
<ol start="2" style="list-style-type: decimal">
<li>różnica dwóch wariancji: <span class="math display">\[H_{0}:\;\sigma^2_1-\sigma^2_2=d_0\quad\textrm{vs.}\quad H_{1}:\;\sigma^2_1-\sigma^2_2\neq d_0\]</span> Statystyka testu: <span class="math display">\[Z=\frac{\big(\hat{\sigma}^2_1-\hat{\sigma}^2_2\big)-d_0}{SE_{\hat{\sigma}^2_1-\hat{\sigma}^2_2}}\quad\longrightarrow\quad N(0,1)\]</span> gdzie: <span class="math inline">\(SE_{\hat{\sigma}^2_1-\hat{\sigma}^2_2}=\sqrt{\frac{\textrm{Var}(x_{i}-\hat{\mu})^2}{n_1}+\rho^2_{}\cdot \frac{\textrm{Var}(y_i-\hat{\mu})^2}{n_2}}\)</span> to błąd standardowy różnicy wariancji, <span class="math inline">\(\rho^2\)</span> to opcjonalny parametr do osłabienia/wzmocnienia udziału drugiej wariancji.</li>
</ol>
<pre class="r"><code>asympTest::asymp.test(d$x, d$y, rho= 1, par= &quot;dVar&quot;, ref= 0)</code></pre>
<pre><code>## 
##  Two-sample asymptotic difference of variances test
## 
## data:  d$x and d$y
## statistic = -2.6919, p-value = 0.007105
## alternative hypothesis: true difference of variances is not equal to 0
## 95 percent confidence interval:
##  -3.3838851 -0.5324238
## sample estimates:
## difference of variances 
##               -1.958154</code></pre>
<p>Test Bartletta, Fligner-Killen lub Levene przeważnie są stosowane dla kilku wariancji ale nic nie stoi na przeszkodzie aby wykorzystać je do testowania dwóch wariancji. W przeciwieństwie do testu Bartletta dwa ostatnie testy są mało wrażliwe na odchylenie od rozkładu normalnego w próbkach <span class="citation">(Biecek <a href="#ref-biecek2017">2017</a>, <em>pg. 256-258</em>)</span>. Dodajmy, że test Levene i Fligner-Killeen mogą występować w trzech wariantach tzn. za parametr lokalizacji można przyjąć średnią, średnią uciętą lub medianę.</p>
<pre class="r"><code>d2 &lt;- stack(d)
lawstat::levene.test(d2$values, d2$ind, location =&quot;trim.mean&quot;, trim.alpha= 0.2,
                     bootstrap= TRUE, num.bootstrap= 1000)</code></pre>
<pre><code>## 
##  bootstrap modified robust Levene-type test based on the absolute
##  deviations from the trimmed mean ( none not applied because the
##  location is not set to median )
## 
## data:  d2$values
## Test Statistic = 6.0332, p-value = 0.025</code></pre>
<pre class="r"><code>coin::fligner_test(values~ ind, data= d2, distribution= coin::approximate(B=1000))</code></pre>
<pre><code>## 
##  Approximative Two-Sample Fligner-Killeen Test
## 
## data:  values by ind (x, y)
## Z = -1.3754, p-value = 0.195
## alternative hypothesis: true ratio of scales is not equal to 1</code></pre>
</div>
</div>
</div>
<div id="references" class="section level1 unnumbered">
<h1>References</h1>
<div id="refs" class="references">
<div id="ref-bar1982">
<p>Bartels, Robert. 1982. “The Rank Version of von Neumann’s Ratio Test for Randomness.” <em>Journal of the American Statistical Association</em> 77 (377). Taylor &amp; Francis: 40–46. doi:<a href="https://doi.org/10.2307/2287767">10.2307/2287767</a>.</p>
</div>
<div id="ref-biecek2013">
<p>Biecek, P. 2013. “Wybrane Testy Normalności.” SmarterPoland. <a href="http://tofesi.mimuw.edu.pl/~cogito/smarterpoland/samouczki/testyNormalnosci/testyNormalnosci.pdf" class="uri">http://tofesi.mimuw.edu.pl/~cogito/smarterpoland/samouczki/testyNormalnosci/testyNormalnosci.pdf</a>.</p>
</div>
<div id="ref-biecek2017">
<p>———. 2017. <em>Przewodnik Po Pakiecie R</em>. Oficyna Wydawnicza “GIS”. <a href="http://www.biecek.pl/R/" class="uri">http://www.biecek.pl/R/</a>.</p>
</div>
<div id="ref-asym2009">
<p>Coeurjolly, J.-F., R. Drouilhet, P. Lafaye de Micheaux, and J.-F. Robineau. 2009. “asympTest: A Simple R Package for Classical Parametric Statistical Tests and Confidence Intervals in Large Samples.” <em>The R Journal</em> 1 (2): 26–30. <a href="https://journal.r-project.org/archive/2009/RJ-2009-015/index.html" class="uri">https://journal.r-project.org/archive/2009/RJ-2009-015/index.html</a>.</p>
</div>
<div id="ref-hd1982">
<p>Harrel, F. E., and C. E. Davis. 1982. “A New Distribution-Free Quantile Estimator.” <em>Biometrika</em> 69 (3): 635–40. <a href="http://dx.doi.org/10.1093/biomet/69.3.635" class="uri">http://dx.doi.org/10.1093/biomet/69.3.635</a>.</p>
</div>
<div id="ref-hs1986">
<p>Hettmansperger, T. P., and S. J. Sheather. 1986. “Confidence Intervals Based on Interpolated Order Statistics.” <em>Statistics and Probability Letters</em> 4 (2): 75–79. <a href=" https://doi.org/10.1016/0167-7152(86)90021-0 ">https://doi.org/10.1016/0167-7152(86)90021-0</a>.</p>
</div>
<div id="ref-lafa2016">
<p>Lafaye de Micheaux, Pierre, and Viet Anh Tran. 2016. “PoweR: A Reproducible Research Tool to Ease Monte Carlo Power Simulation Studies for Goodness-of-Fit Tests in R.” <em>Journal of Statistical Software</em> 69 (3): 1–42. doi:<a href="https://doi.org/10.18637/jss.v069.i03">10.18637/jss.v069.i03</a>.</p>
</div>
<div id="ref-mj1978">
<p>Maritz, J. S., and R. G. Jarrett. 1978. “A Note on Estimating the Variance of the Sample Median.” <em>Journal of the American Statistical Association</em> 73 (361). Taylor &amp; Francis: 194–96. doi:<a href="https://doi.org/10.1080/01621459.1978.10480027">10.1080/01621459.1978.10480027</a>.</p>
</div>
<div id="ref-ms1984">
<p>McKean, J. W., and R. M. Schrader. 1984. “A Comparison of Methods for Studentizing the Sample Median.” <em>Communications in Statistics - Simulation and Computation</em> 13 (6). Taylor &amp; Francis: 751–73. <a href=" https://doi.org/10.1080/03610918408812413 ">https://doi.org/10.1080/03610918408812413</a>.</p>
</div>
<div id="ref-dbgof2013">
<p>Miecznikowski, J. C., A. Vexler, and L. A. Shepherd. 2013. “dbEmpLikeGOF: An R Package for Nonparametric Likelihood Ratio Tests for Goodness-of-Fit and Two-Sample Comparisons Based on Sample Entropy.” <em>Journal of Statistical Software</em> 54 (3): 1–19. doi:<a href="https://doi.org/10.18637/jss.v054.i03">10.18637/jss.v054.i03</a>.</p>
</div>
<div id="ref-nb1992">
<p>Nyblom, J. 1992. “Note on Interpolated Order Statistics.” <em>Statistics and Probability Letters</em> 14 (2): 129–31. <a href="https://doi.org/10.1016/0167-7152(92)90076-H" class="uri">https://doi.org/10.1016/0167-7152(92)90076-H</a>.</p>
</div>
<div id="ref-tmc1963">
<p>Tukey, J. W., and D. H. McLaughlin. 1963. “Less Vulnerable Confidence and Significance Procedures for Location Based on a Single Sample:trimming/Winsorization 1.” <em>Sankhya</em> 25: 331–52.</p>
</div>
<div id="ref-wald1940">
<p>Wald, A., and J. Wolfowitz. 1940. “On a Test Whether Two Samples Are from the Same Population.” <em>Ann. Math. Statist.</em> 11 (2). The Institute of Mathematical Statistics: 147–62. doi:<a href="https://doi.org/10.1214/aoms/1177731909">10.1214/aoms/1177731909</a>.</p>
</div>
<div id="ref-Wang2003">
<p>Wang, Ying. 2003. “Nonparametric Tests for Randomness.” In. <a href="https://www.semanticscholar.org/paper/Nonparametric-Tests-for-Randomness-Wang/d915b72beb98760cba78b258dfbd11179fec8a27" class="uri">https://www.semanticscholar.org/paper/Nonparametric-Tests-for-Randomness-Wang/d915b72beb98760cba78b258dfbd11179fec8a27</a>.</p>
</div>
<div id="ref-wilcox2017">
<p>Wilcox Rand. 2017. <em>Introduction to Robust Estimation and Hypothesis Testing 4th Edition</em>. Elsevier. <a href="https://www.elsevier.com/books/introduction-to-robust-estimation-and-hypothesis-testing/wilcox/978-0-12-804733-0" class="uri">https://www.elsevier.com/books/introduction-to-robust-estimation-and-hypothesis-testing/wilcox/978-0-12-804733-0</a>.</p>
</div>
</div>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
